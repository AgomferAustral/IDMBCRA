---
title: "TPAle 02"
author: "Gomez Fernandez, Alejandro"
date: "`r Sys.Date()`"
output:
  html:
    toc: true            # Tabla de contenidos
    toc_float: true      # TOC flotante para facilitar la navegaci√≥n
    number_sections: true # Numera secciones
    theme: cosmo         # Tema visual (puede ser: cosmo, flatly, lumen, etc.)
    highlight: tango     # Resaltado de sintaxis
    self_contained: false # Archivos CSS/JS/imagenes separados, reduce peso HTML
    df_print: paged      # Tablas con paginaci√≥n
    keep_md: false       # No conserva el markdown intermedio
    code_folding: hide   # C√≥digo R oculto por defecto, se puede expandir
editor_options:
  chunk_output_type: console # Muestra output en la consola, m√°s r√°pido en RStudio
knitr:
  opts_chunk:
    echo: false         # Oculta c√≥digo por defecto, se puede cambiar en chunks
    cache: true         # Cachea resultados para evitar recalcular
    warning: false      # Oculta warnings
    message: false      # Oculta mensajes
    error: false        # Oculta errores (solo si est√°s seguro)
    fig.width: 6        # Ancho predeterminado de gr√°ficos
    fig.height: 4       # Alto predeterminado de gr√°ficos
    dpi: 150            # Resoluci√≥n de gr√°ficos
    fig.align: "center" # Alinea gr√°ficos al centro
    fig.path: "figuras/" # Carpeta para guardar im√°genes
    cache.path: "cache/" # Carpeta para el cach√©
execute:
  cache: true
  freeze: auto
  eval: true
  workers: 4
---

# Introduccion

# Resoluci√≥n

## Inicializacion del entorno

```{r Inicializacion, cache=TRUE}

options(warn = -1)

# Importar bibliotecas
knitr::opts_chunk$set(echo = TRUE)

listofpackages <- c("corrplot", "dplyr", "FactoMineR", "factoextra", "GGally",
                    "ggfortify", "ggplot2", "ggrepel", "grid", "gridExtra", "gtExtras", 
                    "kableExtra", "knitr", "pastecs", "psych", "readr", "skimr",
                    "tidyverse")
# Cita de C√≥digo
# C√≥digo tomado de: https://github.com/lkovalevski/textsimilaritiesinR/tree/691b5798553d81a86b6c151557c4a667f8c58643/ejecutarAnalisisTexto.R
# Autor: lkovalevski
#
newPackages <- listofpackages[ !(listofpackages %in% installed.packages()[, "Package"])]
if(length(newPackages)) install.packages(newPackages)
for (paquete in listofpackages) {
  suppressMessages(library(paquete, character.only = TRUE))
}


# Funcion para liberar memoria guardando los dataframes procesados
guardar_y_limpiar <- function(df) {
  # Generamos el nombre del archivo
  nombre_archivo <- deparse(substitute(df))

  # Verificamos si la carpeta "datos_intermedios" existe, si no, crearla
  if (!dir.exists("datos_intermedios")) {
    dir.create("datos_intermedios")
  }
  
  # Creamos la ruta del archivo con extensi√≥n .rds
  archivo <- file.path("datos_intermedios", paste0(nombre_archivo, ".rds"))
  
  # Guardamos el dataframe en la carpeta en formato RDS
  saveRDS(df, archivo)
  
  # Borramos el dataframe de la memoria
  rm(list = nombre_archivo, envir = .GlobalEnv)
  
  # Limpiamos la memoria (recolectar basura)
  invisible(gc(full = TRUE))
  
  # Confirmamos con mensaje|
  cat("El archivo se ha guardado como", archivo, "y la memoria ha sido limpiada.\n")
} 


```

## Carga y limpieza de datos

```{r Carga_y_limpieza, cache=TRUE}

# Abrimos el archivo que se encuentra en la carpeta datos_entrada
archivo_datos <- readRDS("./datos_entrada/df_bcra_individuals.rds")

# Describimos el dataset

skimr::skim(archivo_datos)
knitr::kable(str(archivo_datos))
knitr::kable(t(head(archivo_datos)))

# Vemos las columnas con datos nulos o faltantes
columnas_con_nulos <- archivo_datos %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "columna", values_to = "num_nulos") %>%
  filter(num_nulos > 0)

knitr::kable(columnas_con_nulos)

# Eliminamos el objeto temporal
rm(columnas_con_nulos)


```

### Preprocesamiento de datos

```{r Preprocesamiento, cache=TRUE}


# Hacemos una copia del dataset para trabajar, manteniendo el original

df_datos <- archivo_datos

guardar_y_limpiar(archivo_datos)



# Nos aseguramos que las columnas num√©ricas solo contienen datos num√©ricos

df_datos <- df_datos %>%
    mutate(across(where(is.numeric), ~ as.numeric(as.character(.))))


# Nos aseguramos que las columnas especificadas sean de tipo categ√≥rico
df_datos <- df_datos %>%
    mutate(across(c(tipo_persona, n_deudas_actual, situacion_mes_actual, tiene_garantia_actual, 
                  max_situacion_mes, max_sit_mes_con_garantia, max_sit_mes_sin_garantia, 
                  peor_situacion_respuesta, mora_mayor_30_dias, default), as.factor))

# Verificamos la estructura del dataset despu√©s de las conversiones
str(df_datos)


# Recodificamos Tipo_persona

df_datos <- df_datos %>%
  mutate(
    sexo_cat = case_when(
      tipo_persona == 20 ~ "Hombre",
      tipo_persona == 27 ~ "Mujer",
      tipo_persona %in% c(23, 24) ~ "Desconocido"
    ),
    sexo_num = case_when(
      tipo_persona == 20 ~ 0,  # Hombre ‚Üí 0
      tipo_persona == 27 ~ 1,  # Mujer ‚Üí 1
      tipo_persona %in% c(23, 24) ~ 2  # Desconocido ‚Üí 2
    )
  )


# Eliminar la columna id_individuo
df_datos <- df_datos %>%
  select(-id_individuo)

# Hacemos un an√°lisis exploratorio inicial de las variables
gt_plt_summary(df_datos, title="Figura 1. An√°lisis exploratorio inicial de las variables en conjunto excluyendo deudas mayores a 100000")


skimr::skim(df_datos)

# Vemos las columnas con datos nulos o faltantes
columnas_con_nulos <- df_datos %>%
    summarise_all(~ sum(is.na(.))) %>%
    pivot_longer(cols = everything(), names_to = "columna", values_to = "num_nulos") %>%
    filter(num_nulos > 0)

knitr::kable(columnas_con_nulos)

# Eliminamos el objeto temporal
rm(columnas_con_nulos)


#############################################################
# Creamos una nueva categor√≠a [0: No aplica] para la variable max_sit_mes_con_garantia para aquellos 
# registros que no tienen deuda con garant√≠a y tienen valor NA
#############################################################


# Asignamos 0 a max_sit_mes_con_garantia si deuda_con_garantia_actual es 0 y max_sit_mes_con_garantia es NA
df_datos <- df_datos %>%
    mutate(max_sit_mes_con_garantia = ifelse(is.na(max_sit_mes_con_garantia) & deuda_con_garantia_actual == 0, 0, max_sit_mes_con_garantia))

# Volver a ver las columnas con datos nulos o faltantes
columnas_con_nulos <- df_datos %>%
    summarise_all(~ sum(is.na(.))) %>%
    pivot_longer(cols = everything(), names_to = "columna", values_to = "num_nulos") %>%
    filter(num_nulos > 0)

knitr::kable(columnas_con_nulos)

# Eliminamos el objeto temporal
rm(columnas_con_nulos)

# Filtramos y seleccionamos las columnas deseadas para registros con max_sit_mes_sin_garantia = NA
registros_con_na <- df_datos %>%
    filter(is.na(max_sit_mes_sin_garantia)) %>%
    select(deuda_total_actual, deuda_con_garantia_actual, prop_con_garantia_actual, tiene_garantia_actual, max_sit_mes_sin_garantia)

# Verificamos los registros filtrados
knitr::kable(head(registros_con_na))

# Eliminamos el objeto temporal
rm(registros_con_na)


# Asignamos 0 a max_sit_mes_sin_garantia si prop_con_garantia_actual es 1 y max_sit_mes_sin_garantia es NA
df_datos <- df_datos %>%
    mutate(max_sit_mes_sin_garantia = ifelse(is.na(max_sit_mes_sin_garantia) & prop_con_garantia_actual == 1, 0, max_sit_mes_sin_garantia))

# Volvemos a ver las columnas con datos nulos o faltantes
columnas_con_nulos <- df_datos %>%
    summarise_all(~ sum(is.na(.))) %>%
    pivot_longer(cols = everything(), names_to = "columna", values_to = "num_nulos") %>%
    filter(num_nulos > 0)

# Verificamos que ya no quedan valores nulos
knitr::kable(columnas_con_nulos)

# Eliminamos el objeto, ahora vacio
rm(columnas_con_nulos)


#############################################################
# Cita de c√≥digo
## Licencia: desconocida
## Autor: Arena, Cristian
## Actualizaci√≥n: Ajuste con par√°metros de corte y coeficientes propios
#############################################################


# Funci√≥n para calcular el rango de edad
calcular_rango_edad_2019 <- function(proxy_edad_actual) {
  if (is.na(proxy_edad_actual)) {
    return(NA)
  }
  
  # Calculamos a√±o de nacimiento
  if (proxy_edad_actual >= 500) {
    anio_nacimiento <- 2010 + floor((proxy_edad_actual - 500)/10)
  } else if (proxy_edad_actual >= 424) {
    anio_nacimiento <- 2000 + floor((proxy_edad_actual - 424)/7.6)
  } else if (proxy_edad_actual >= 284) {
    anio_nacimiento <- 1980 + floor((proxy_edad_actual - 284)/7)
  } else if (proxy_edad_actual >= 217) {
    anio_nacimiento <- 1970 + floor((proxy_edad_actual - 217)/6.7)
  } else if (proxy_edad_actual >= 142) {
    anio_nacimiento <- 1960 + floor((proxy_edad_actual - 142)/7.5)
  } else if (proxy_edad_actual >= 45) {
    anio_nacimiento <- 1940 + floor((proxy_edad_actual - 45)/4.85)
  } else {
    anio_nacimiento <- 1920 + floor((proxy_edad_actual - 20) / 1.25)
  }
  
  # Calculamos edad en 2019
  edad_2019 <- 2019 - anio_nacimiento
  
  # Asignamos rango de edad
  if (edad_2019 < 20) {
    rango_edad <- "<20"
  } else if (edad_2019 <= 30) {
    rango_edad <- "20-29"
  } else if (edad_2019 <= 40) {
    rango_edad <- "30-39"
  } else if (edad_2019 <= 50) {
    rango_edad <- "40-49"
  } else if (edad_2019 <= 60) {
    rango_edad <- "50-60"
  } else {
    rango_edad <- ">60"
  }
  
  return(rango_edad)
}

# Creamos nueva columna con rango de edad calculado para cada individuo

df_datos <- df_datos %>%
  mutate(rango_edad_2019 = map(proxy_edad_actual, calcular_rango_edad_2019) %>% unlist())

# Mostramos un resumen de los resultados
print("Resumen de rangos de edad al 2019:")
knitr::kable(table(df_datos$rango_edad_2019))

# Mostramos algunas filas de ejemplo
print("Ejemplos de registros con el rango de edad al 2019:")
knitr::kable(head(df_datos[, c("proxy_edad_actual", "rango_edad_2019")]))


df_datos <- df_datos %>%
  mutate(
    cat_edad = case_when(
      rango_edad_2019 == "<20"    ~ 0,
      rango_edad_2019 == "20-29"  ~ 1,
      rango_edad_2019 == "30-39"  ~ 2,
      rango_edad_2019 == "40-49"  ~ 3,
      rango_edad_2019 == "50-60"  ~ 4,
      TRUE                        ~ 5  # Cualquier otro valor
    )
  )


# Aseguramos que la columna rango_edad_2019 sea de tipo categ√≥rico
df_datos <- df_datos %>%
    mutate(rango_edad_2019 = as.factor(rango_edad_2019),
          sexo_cat = as.factor(sexo_cat)
          )


```

### Seleccionamos el conjunto de datos para trabajar

```{r Seleccion_datos, cache=TRUE}

#############################################################
#
# Verificamos la cantidad de registros que no cumplen la condici√≥n del enunciado
#
#    Con respecto al trabajo final les quer√≠amos avisar que si bien en el
#    enunciado dice que la muestra utilizada est√° compuesta por cuits cuyo 
#    "monto total adeudado en ese momento no superaba los 100.000 pesos 
#    argentinos.", en la base quedaron algunos casos (1705) que s√≠ tienen 
#    deuda total en junio 2019 mayor a 100.000.
# 
#############################################################

cant <- sum(df_datos$deuda_total_actual > 100, na.rm = TRUE)
print(paste("Cantidad de registros estrictamente mayores a 100:", cant))

cant <- sum(df_datos$deuda_total_actual >= 100, na.rm = TRUE)
print(paste("Cantidad de registros mayores o iguales a 100:", cant))

#############################################################
# Y porque los n√∫meros est√°n redondeados a miles, voy a filtrar los valores
# mayores o iguales a 100 en el campo deuda_total_actual, luego de 
# verificar que a esa condici√≥n 1705 registros la cumplen.
#############################################################

# Filtramos filas con deuda_total_actual mayor a 100
filas_con_deuda_mayor_100 <- df_datos %>%
    filter(deuda_total_actual >= 100)

# Excluir registros con deuda_total_actual mayor a 100
df_seleccionados <- df_datos %>%
    filter(deuda_total_actual < 100)

# Vemos las filas con deuda_total_actual mayor a 100
knitr::kable(head(filas_con_deuda_mayor_100))

# Eliminamos dataframe con deudas mayores ao iguales a 100
rm(filas_con_deuda_mayor_100)

# Guardamos el dataframe procesado con todos los datos 
guardar_y_limpiar(df_datos)

```






## Comenzamos el analisis exploratorio

```{r EDA, cache=TRUE}


# Hacemos un an√°lisis exploratorio inicial de las variables
gt_plt_summary(df_seleccionados, title="Figura 2. An√°lisis exploratorio inicial de las variables en conjunto excluyendo deudas mayores a 100000, sin valores nulos")


```
### An√°lisis univariado

```{r Analisis_univariado, cache=TRUE}

# Obtenemos estadisticos
df2 <- pastecs::stat.desc(df_seleccionados) %>% as.matrix %>% as.data.frame %>% round(2)

# Eliminamos columnas con NA -> categ√≥ricas
df2_limpia <- df2 %>%
    select(where(~ !any(is.na(.))))

df2_limpia <- format(df2_limpia, scientific = FALSE)

knitr::kable(t(data.frame(df2_limpia)), digits = 2)

# Utilizamos la funci√≥n skim para describir la distribuci√≥n univariada de cada columna
skimr::skim(df2_limpia)

# Guardamos el archivo con datos de la distribucion
guardar_y_limpiar(df2)
guardar_y_limpiar(df2_limpia)



```

#### Hacemos graficos de distribucion

```{r Graficos, cache=TRUE}

#############################################################
# Calculamos el n√∫mero √≥ptimo de bins (intervalos) para el histograma utilizando 
# la regla de Freedman-Diaconis a trav√©s de la funci√≥n nclass.FD del paquete MASS

# La Regla de Freedman-Diaconis es un m√©todo para determinar el tama√±o √≥ptimo de 
# los bins (intervalos) en un histograma. Busca un balance entre precisi√≥n y suavidad
# en la distribuci√≥n de los datos, evitando histogramas con demasiados o muy pocos bins.

# F√≥rmula de Freedman-Diaconis
# Bin width=2√óIQRn1/3
# Bin width=2√ón1/3IQR‚Äã

# Donde:

#    IQR = Rango intercuart√≠lico (diferencia entre el cuartil 3 y el cuartil 1).
#    n = N√∫mero total de observaciones (tama√±o de la muestra).
#    Bin width = Ancho del intervalo del histograma.

# üìå ¬øPor qu√© se usa el IQR?

#    Es robusto frente a valores at√≠picos (outliers).
#    Proporciona una mejor representaci√≥n de la dispersi√≥n de los datos que la
#    desviaci√≥n est√°ndar.
#############################################################



# Funci√≥n para crear gr√°ficos de distribuci√≥n
plot_distribution <- function(data, column) {
  if (is.numeric(data[[column]])) {
    # Calculamos el n√∫mero √≥ptimo de bins usando la regla de Freedman-Diaconis
    num_bins <- nclass.FD(data[[column]])
    ggplot(data, aes(x = .data[[column]])) +
      geom_histogram(bins = num_bins, fill = "blue", color = "black") +
      labs(title = paste("Distribuci√≥n de", column), x = column, y = "Frecuencia") +
      theme_minimal()+
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
  } else if (is.factor(data[[column]])) {
    ggplot(data, aes(x = .data[[column]])) +
      geom_bar(fill = "blue", color = "black") +
      labs(title = paste("Distribuci√≥n de", column), x = column, y = "Frecuencia") +
      theme_minimal()+
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
  }
}

# Creamos una lista de gr√°ficos de distribuci√≥n para cada columna
plots <- map(colnames(df_seleccionados), ~ plot_distribution(df_seleccionados, .x))


# Presentamos los gr√°ficos en una matriz
do.call(grid.arrange, c(plots, ncol = 3))



# Funci√≥n para crear boxplots
plot_boxplot <- function(data, column) {
  ggplot(data, aes(y = .data[[column]])) +
    geom_boxplot(fill = "blue", color = "black") +
    labs(title = paste("Boxplot de", column), y = column) +
    theme_minimal()+
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

# Creamos una lista de gr√°ficos de boxplot para cada columna num√©rica
boxplots <- map(names(df_seleccionados), ~ {
  if (is.numeric(df_seleccionados[[.x]])) {
    plot_boxplot(df_seleccionados, .x)
  } else {
    NULL
  }
}) %>% compact()

# Presentamos los gr√°ficos en una matriz
do.call(grid.arrange, c(boxplots, ncol = 3))

# Guardamos la lista de los boxplots
guardar_y_limpiar(boxplots)

```




### Outliers

```{r Outliers, cache=TRUE}

# Outliers

# Funci√≥n para identificar outliers usando el IQR
identify_outliers <- function(data, column) {
  Q1 <- quantile(data[[column]], 0.25, na.rm = TRUE)
  Q3 <- quantile(data[[column]], 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  outliers <- data %>%
    filter(.data[[column]] < lower_bound | .data[[column]] > upper_bound)
  return(outliers)
}

# Identificamos outliers para cada columna num√©rica
outliers_list <- map(names(df_seleccionados), ~ {
  if (is.numeric(df_seleccionados[[.x]])) {
    outliers <- identify_outliers(df_seleccionados, .x)
    if (nrow(outliers) > 0) {
      return(list(column = .x, outliers = outliers))
    }
  }
  return(NULL)
}) %>% compact()

# Mostramos los outliers identificados
walk(outliers_list, ~ {
  cat("Outliers en la columna:", .x$column, "\n")
  
  # Ordenamos los outliers de menor a mayor
  sorted_outliers <- .x$outliers %>% arrange(.data[[.x$column]])
  
  # Mostramos los 5 outliers m√°s bajos
  cat("5 outliers m√°s bajos:\n")
  print(head(sorted_outliers, 5))
  
  # Mostramos los 5 outliers m√°s altos
  cat("5 outliers m√°s altos:\n")
  print(tail(sorted_outliers, 5))
  
  # Mostramos la cantidad total de outliers
  cat("Cantidad total de outliers:", nrow(.x$outliers), "\n\n")
})

# Borramos la lista de outliers
guardar_y_limpiar(outliers_list)


```

### Correlaciones

```{r Correlaciones, cache=TRUE}

# Correlaciones


#############################################################
# Eliminamos las columnas categoricas no ordinales y hacer ordinales aquellas 
# que puedan serlo
#############################################################


# Filtramos las columnas num√©ricas del DataFrame
col_numericas <- df_seleccionados %>%
  select_if(is.numeric)

# Calculamos la matriz de correlaciones
matriz_corr <- cor(col_numericas, use = "complete.obs")

# Mostramos la matriz de correlaciones
print(matriz_corr)

# Visualizamos la matriz de correlaciones
corrplot(matriz_corr, method = "color", type = "upper", 
        tl.col = "black", tl.srt = 45, addCoef.col = "black")


# Guardamos el gr√°fico en un archivo PNG
png("pairs_panels.png", width = 1200, height = 1200)
par(mar = c(2, 2, 2, 2))
options(repr.plot.width = 10, repr.plot.height = 8)  # Ajusta el ancho y alto

# Creamos el gr√°fico de pares
pairs.panels(
  col_numericas,
  method = "pearson",  # correlation
  hist.col = "#00AFBB",
  density = TRUE,      # show density
  ellipses = T     # show correlation ellipses
)

# Cerramos el dispositivo PNG
dev.off()


# Gr√°fico de pares alternativo
ggpairs(
  col_numericas,
  title = "Gr√°fico de Pares de Variables Num√©ricas",
  upper = list(continuous = wrap("cor", size = 4)),
  lower = list(continuous = wrap("smooth", alpha = 0.5, size = 0.1)),
  diag = list(continuous = wrap("barDiag", fill = "blue", color = "black")),
  axisLabels = "show"
) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )


# Borramos la matriz que ya no usamos
guardar_y_limpiar(matriz_corr)

# Guardamos las imagenes que ya no usamos
guardar_y_limpiar(plots)

```







### PCA

```{r PCA, cache=TRUE}

# PCA

# Realizar el an√°lisis de componentes principales (PCA)
pca_result <- prcomp(col_numericas, scale. = TRUE)

# Resumen del PCA
summary(pca_result)

# Porcentaje de la variabilidad total explicada por las dos primeras componentes
var_explicada <- summary(pca_result)$importance[2, 1:2]
cat("Porcentaje de la variabilidad total explicada por las dos primeras componentes:\n")
print(var_explicada)

# Creamos un DataFrame con las componentes principales
pca_df <- as.data.frame(pca_result$x)

# A√±adimos la columna tipo_persona al DataFrame de PCA
pca_df <- pca_df %>%
  mutate(sexo_cat = df_seleccionados$sexo_cat)

# Visualizamos las dos primeras componentes principales
ggplot(pca_df, aes(x = PC1, y = PC2, color = sexo_cat)) +
  geom_point(alpha = 0.5) +
  labs(title = "PCA: Primeras dos componentes principales",
      x = "Componente Principal 1",
      y = "Componente Principal 2") +
  theme_minimal()

# Interpretaci√≥n de los componentes
cat("Cargas de las variables en las dos primeras componentes:\n")
print(pca_result$rotation[, 1:2])


df_seleccionados <- df_seleccionados %>%
    mutate(sexo_num = as.factor(sexo_num),
        cat_edad = as.factor(cat_edad))

plot_pca <- autoplot(pca_result, 
        data = df_seleccionados, 
        colour = 'sexo_cat', 
        loadings = TRUE, 
        loadings.label = TRUE, 
        loadings.label.size = 3)

plot_pca + scale_color_manual(values = c("Mujer" = "green", "Hombre" = "blue", "Desconocido" = "red"))


```

## 
```{r}


```

## 

```{r}

```